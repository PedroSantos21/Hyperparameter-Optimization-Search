{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trabalho iremos fazer a busca dos melhores hiperparametros de uma SVM para Regressão num banco de dados em particular. Para o desenvolvimento utilizaremos a biblioteca sklearn.svm que apresenta a função  SVR() que implementa o regressor SVM e tem vários hiperparametros.\n",
    "Vamos usar o kernel “rbf”, havendo 3 hiperparametros que consideramos como os mais importantes: C, gamma, e epsilon.\n",
    "\n",
    "Vamos fazer a busca no range:\n",
    "    - C entre 2^{-5} e 2^{15}  (uniforme nos expoentes);\n",
    "    - gamma entre 2^{15} e 2^{-3} (uniforme nos expoentes);\n",
    "    - episolon entre 0.05 e 10  (uniforme neste intervalo);\n",
    "    \n",
    "Utilizamos como dados de treino e testes os arquivos Xtreino5.npy e Xteste5.npy. Para as sáidas dos dados correspondenetres usamos os arquivos ytreino5.npy e yteste5.npy. Todos os arquivos foram disponibilizados na página no trabalho https://www.ic.unicamp.br/~wainer/cursos/1s2020/431/ex4.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primeiro passo, importamos as bibliotecas necessárias para a implementação desse trabalho: numpy e sklearn.svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\renat\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import metrics\n",
    "import pyspark\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from simulated_annealing.optimize import SimulatedAnneal\n",
    "from pyswarm import pso\n",
    "from simanneal import Annealer\n",
    "import cma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e Exibição dos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após importamos as bibliotecas necessárias, realizamos a leitura dos arquivos .npy disponibilizados para uso neste trabalho. Para isso fizemos uso da função load() da biblioteca numpy. Armazenamos cada um dos arquivos de treino e de teste em variáveis locais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = np.load('data/Xtreino5.npy')\n",
    "x_teste = np.load('data/Xteste5.npy')\n",
    "y_treino = np.load('data/ytreino5.npy')\n",
    "y_teste = np.load('data/yteste5.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medida de erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primeira tarefa, para cada conjunto de hiperparametros, treinamos o SVM no conjunto de treino (Xtreino e ytreino), e medimos o erro absoluto médio (MAE) no conjunto de teste (Xteste e yteste)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combinations = 125\n",
    "\n",
    "# Hyperparameters Search Space\n",
    "C_range = np.random.uniform(-5, 15, n_combinations).astype(float)\n",
    "C_range = 2**C_range\n",
    "\n",
    "gamma_range = np.random.uniform(-15, 3, n_combinations).astype(float)\n",
    "gamma_range = 2**gamma_range\n",
    "\n",
    "epsilon_range = np.random.uniform(0.05, 1.0, n_combinations).astype(float)\n",
    "\n",
    " \n",
    "hyperparameters = {'gamma': list(gamma_range), \n",
    "                    'C': list(C_range),\n",
    "                  'epsilon': list(epsilon_range)}\n",
    " \n",
    "# print (hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run randomized search\n",
    "randomCV = RandomizedSearchCV(SVR(kernel='rbf'), param_distributions=hyperparameters, n_iter=20)\n",
    "randomCV.fit(x_treino, y_treino)\n",
    " \n",
    "# Identify optimal hyperparameter values\n",
    "best_gamma  = randomCV.best_params_['gamma']\n",
    "best_C      = randomCV.best_params_['C']\n",
    "best_epsilon= randomCV.best_params_['epsilon']\n",
    "\n",
    "print(\"The best performing C value is: {:5.2f}\".format(best_C))\n",
    "print(\"The best performing gamma value is: {:5.5f}\".format(best_gamma))\n",
    "print(\"The best performing epsilon value is: {:5.2f}\".format(best_epsilon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "svr  = SVR(kernel='rbf', gamma=best_gamma, epsilon=best_epsilon, C=best_C)\n",
    "svr.fit(x_treino, y_treino)\n",
    "\n",
    "pred = svr.predict(x_teste)\n",
    "\n",
    "# print(regression.score(x_teste, y_teste))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_true=y_teste, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid seach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo algoritimo de otimização proposto foi o Grid Search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_c = C_range.reshape((5,5,5))\n",
    "grid_gamma = gamma_range.reshape((5,5,5))\n",
    "grid_episolon = epsilon_range.reshape((5,5,5))\n",
    "\n",
    "hyperparameters_grid = [{'gamma': grid_gamma[0][0,:5], 'C': grid_c[0][0,:5], 'epsilon': grid_episolon[0][0,:5]},\n",
    "                       {'gamma': grid_gamma[0][1,:5], 'C': grid_c[0][1,:5], 'epsilon': grid_episolon[0][1,:5]},\n",
    "                       {'gamma': grid_gamma[0][2,:5], 'C': grid_c[0][2,:5], 'epsilon': grid_episolon[0][2,:5]},\n",
    "                       {'gamma': grid_gamma[0][3,:5], 'C': grid_c[0][3,:5], 'epsilon': grid_episolon[0][3,:5]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run randomized search\n",
    "randomCV = GridSearchCV(SVR(kernel='rbf'), param_grid=hyperparameters_grid, cv = 5)\n",
    "randomCV.fit(x_treino, y_treino)\n",
    " \n",
    "# Identify optimal hyperparameter values\n",
    "best_gamma  = randomCV.best_params_['gamma']\n",
    "best_C      = randomCV.best_params_['C']\n",
    "best_epsilon= randomCV.best_params_['epsilon']\n",
    " \n",
    "print(\"The best performing gamma value is: {:5.5f}\".format(best_gamma))\n",
    "print(\"The best performing C value is: {:5.2f}\".format(best_C))\n",
    "print(\"The best performing epsilon value is: {:5.2f}\".format(best_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "svr  = SVR(kernel='rbf', gamma=best_gamma, epsilon=best_epsilon, C=best_C)\n",
    "svr.fit(x_treino, y_treino)\n",
    "\n",
    "pred = svr.predict(x_teste)\n",
    "\n",
    "# print(regression.score(x_teste, y_teste))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_true=y_teste, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro algoritimo proposto foi a otimização bayesiana. Para a sua implementação utilziamos a biblioteca hyperopt, que dispnibiliza O regressor (TPE) para modelar a distribuição de probabilidades que é muito mais rápido que a implementação padrão utilizando “processos gaussianos”.\n",
    "\n",
    "Esta implementação foi feita em passos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir a Função de mínimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos pesquisar por Support Vector Machines (SVM), definimos um parâmetro params ['type'] como o nome do modelo, e uma função para executar o treinamento e retornar a precisão da validação cruzada. \n",
    "Como estamos tentando maximizar a precisão da validação cruzada, devemos negar esse valor para o hyperopt, pois o hyperopt sabe apenas como minimizar uma função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_status(clf,X_,y):\n",
    "    acc = cross_val_score(clf, X_, y, cv=5).mean()\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVR(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    accuracy = cross_val_score(clf, x_treino, y_treino).mean()\n",
    "    \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir espaço de pesquisa sobre os hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.uniform('C', (2**-5), (2**15)),\n",
    "        'gamma': hp.uniform('gamma', (2**-15), (2**3)),\n",
    "        'epsilon': hp.uniform('epsilon', 0.05, 1.0),\n",
    "        'kernel': hp.choice('kernel', ['rbf'])\n",
    "    },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionar um algoritimo de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas opções principais de algoritmos de busca são:\n",
    "\n",
    "    - hyperopt.tpe.suggest: Estimadores da Árvore de Parzen, uma abordagem bayesiana que seleciona iterativa e adaptativamente novas configurações de hiperparâmetro para explorar com base em resultados anteriores;\n",
    "    - hyperopt.rand.suggest: Pesquisa aleatória, uma abordagem não adaptativa que mostra o espaço de pesquisa.\n",
    "    \n",
    "Conforme pedido, utilziamos o algoritimo TPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executar o algoritmo de ajuste com hyperopt fmin ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos max_evals como o número máximo de pontos no espaço do hiperparâmetro para testar, ou seja, o número máximo de modelos para ajustar e avaliar.\n",
    "\n",
    "O SparkTrials usa 2 argumentos:\n",
    "    - parallelism: Número de modelos para ajustar e avaliar simultaneamente.\n",
    "    - timeout: tempo máximo (em segundos) que fmin pode demorar. Este argumento é opcional.\n",
    "\n",
    "O rastreamento automatizado do MLflow está ativado por padrão. Ligue para mlflow.start_run () antes de chamar fmin (), como mostra o exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypopt_trials = Trials()\n",
    " \n",
    "best_params = fmin(objective, search_space, algo=tpe.suggest, \n",
    "max_evals=125, trials= hypopt_trials)\n",
    " \n",
    "best_gamma  = best_params['gamma']\n",
    "best_C      = best_params['C']\n",
    "best_epsilon= best_params['epsilon']\n",
    " \n",
    "print(\"The best performing gamma value is: {:5.5f}\".format(best_gamma))\n",
    "print(\"The best performing C value is: {:5.2f}\".format(best_C))\n",
    "print(\"The best performing epsilon value is: {:5.2f}\".format(best_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "svr  = SVR(kernel='rbf', gamma=best_gamma, epsilon=best_epsilon, C=best_C)\n",
    "svr.fit(x_treino, y_treino)\n",
    "\n",
    "pred = svr.predict(x_teste)\n",
    "\n",
    "# print(regression.score(x_teste, y_teste))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_true=y_teste, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "C_MIN = 2**(-5)\n",
    "C_MAX = 2**15\n",
    "\n",
    "GAMMA_MIN = 2**(-15)\n",
    "GAMMA_MAX = 2**3\n",
    "\n",
    "EPSILON_MIN = 0.05\n",
    "EPSILON_MAX = 1.0\n",
    "\n",
    "lb = [C_MIN, GAMMA_MIN, EPSILON_MIN]\n",
    "ub = [C_MAX, GAMMA_MAX, EPSILON_MAX]\n",
    "\n",
    "# FUNCTION\n",
    "def svr_fun(X):\n",
    "    c = X[0]\n",
    "    g = X[1]\n",
    "    eps = X[2]\n",
    "    \n",
    "    svr  = SVR(kernel='rbf', C=c, gamma=g, epsilon=eps)\n",
    "    svr.fit(x_treino, y_treino)\n",
    "    \n",
    "    pred = svr.predict(x_teste)\n",
    "    mae = metrics.mean_absolute_error(y_true=y_teste, y_pred=pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "print(\"PSO...\")\n",
    "x_opt, y_opt = pso(svr_fun, lb, ub, swarmsize=11, maxiter=11)\n",
    "\n",
    "print(\" C optimal: \"+ str(x_opt[0])+\n",
    "     \"\\n Gamma Optimal: \"+ str(x_opt[1])+\n",
    "     \"\\n Epsilon Optimal: \"+ str(x_opt[2]))\n",
    "print(\"MAE: \", str(y_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Number of possible iterations given cooling schedule: 160\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SimulatedAnneal' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7ad37182e9be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trans\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_runtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                          cv=3, scoring='f1_macro', refit=True)\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_treino\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_treino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# Print the best score and the best params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#print(sa.best_score_, sa.best_params_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SimulatedAnneal' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "svr_params = {'C': C_range,\n",
    "              'gamma': gamma_range,\n",
    "              'epsilon': epsilon_range}\n",
    "\n",
    "# Using a linear SVM classifier             \n",
    "clf = SVR(kernel='rbf')\n",
    "# Initialize Simulated Annealing and fit\n",
    "sa = SimulatedAnneal(clf, svr_params, T=10.0, T_min=0.001, alpha=0.75,\n",
    "                         verbose=True, max_iter=125, n_trans=5, max_runtime=300,\n",
    "                         cv=3, scoring='f1_macro', refit=True)\n",
    "sa.score(x_treino, y_treino)\n",
    "# Print the best score and the best params\n",
    "#print(sa.best_score_, sa.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
