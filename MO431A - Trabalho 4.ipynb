{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trabalho iremos fazer a busca dos melhores hiperparametros de uma SVM para Regressão num banco de dados em particular. Para o desenvolvimento utilizaremos a biblioteca sklearn.svm que apresenta a função  SVR() que implementa o regressor SVM e tem vários hiperparametros.\n",
    "Vamos usar o kernel “rbf”, havendo 3 hiperparametros que consideramos como os mais importantes: C, gamma, e epsilon.\n",
    "\n",
    "Vamos fazer a busca no range:\n",
    "    - C entre 2^{-5} e 2^{15}  (uniforme nos expoentes);\n",
    "    - gamma entre 2^{15} e 2^{-3} (uniforme nos expoentes);\n",
    "    - episolon entre 0.05 e 10  (uniforme neste intervalo);\n",
    "    \n",
    "Utilizamos como dados de treino e testes os arquivos Xtreino5.npy e Xteste5.npy. Para as sáidas dos dados correspondenetres usamos os arquivos ytreino5.npy e yteste5.npy. Todos os arquivos foram disponibilizados na página no trabalho https://www.ic.unicamp.br/~wainer/cursos/1s2020/431/ex4.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das Bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primeiro passo, importamos as bibliotecas necessárias para a implementação desse trabalho: numpy e sklearn.svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import metrics\n",
    "import pyspark\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pyswarm import pso\n",
    "import optuna\n",
    "from scipy.stats import loguniform\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e Exibição dos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após importamos as bibliotecas necessárias, realizamos a leitura dos arquivos .npy disponibilizados para uso neste trabalho. Para isso fizemos uso da função load() da biblioteca numpy. Armazenamos cada um dos arquivos de treino e de teste em variáveis locais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = np.load('data/Xtreino5.npy')\n",
    "x_teste = np.load('data/Xteste5.npy')\n",
    "y_treino = np.load('data/ytreino5.npy')\n",
    "y_teste = np.load('data/yteste5.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medida de erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primeira tarefa, para cada conjunto de hiperparametros, treinamos o SVM no conjunto de treino (Xtreino e ytreino), e medimos o erro absoluto médio (MAE) no conjunto de teste (Xteste e yteste)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combinations = 125\n",
    "\n",
    "# Hyperparameters Search Space\n",
    "C_range = np.random.uniform(-5, 15, n_combinations).astype(float)\n",
    "C_range = 2**C_range\n",
    "\n",
    "# C_range = loguniform(2**-5, 2**15).rvs(size=n_combinations)\n",
    "\n",
    "gamma_range = np.random.uniform(-15, 3, n_combinations).astype(float)\n",
    "gamma_range = 2**gamma_range\n",
    "\n",
    "# gamma_range = loguniform(2**-15, 2** 3).rvs(size=n_combinations)\n",
    "\n",
    "epsilon_range = np.random.uniform(0.05, 1.0, n_combinations).astype(float)\n",
    "\n",
    " \n",
    "hyperparameters = {'gamma': list(gamma_range), \n",
    "                    'C': list(C_range),\n",
    "                  'epsilon': list(epsilon_range)}\n",
    " \n",
    "# print (hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing C value is: 188.52\n",
      "The best performing gamma value is: 0.00009\n",
      "The best performing epsilon value is:  0.45\n"
     ]
    }
   ],
   "source": [
    "# Run randomized search\n",
    "randomCV = RandomizedSearchCV(SVR(kernel='rbf'), param_distributions=hyperparameters, n_iter=20)\n",
    "randomCV.fit(x_treino, y_treino)\n",
    " \n",
    "# Identify optimal hyperparameter values\n",
    "best_gamma  = randomCV.best_params_['gamma']\n",
    "best_C      = randomCV.best_params_['C']\n",
    "best_epsilon= randomCV.best_params_['epsilon']\n",
    "\n",
    "print(\"The best performing C value is: {:5.2f}\".format(best_C))\n",
    "print(\"The best performing gamma value is: {:5.5f}\".format(best_gamma))\n",
    "print(\"The best performing epsilon value is: {:5.2f}\".format(best_epsilon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3.5487968270739882\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "svr  = SVR(kernel='rbf', gamma=best_gamma, epsilon=best_epsilon, C=best_C)\n",
    "svr.fit(x_treino, y_treino)\n",
    "\n",
    "pred = svr.predict(x_teste)\n",
    "\n",
    "# print(regression.score(x_teste, y_teste))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_true=y_teste, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid seach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo algoritimo de otimização proposto foi o Grid Search. Seguindo a especificação de uma busca em uma grid de 5x5x5, amostras do range de busca foram tomadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Search Space\n",
    "n_combinations = 5\n",
    "\n",
    "# Taken 5 samples randomly\n",
    "grid_c = random.sample(list(C_range), k=n_combinations)\n",
    "grid_gamma = random.sample(list(gamma_range), k=n_combinations)\n",
    "grid_episolon = random.sample(list(epsilon_range), k=n_combinations)\n",
    "\n",
    "# The best performing gamma value is: 0.00021\n",
    "# The best performing C value is: 1425.76\n",
    "# The best performing epsilon value is:  0.91\n",
    "\n",
    "# Generate a uniform distribution with 5 elements\n",
    "# grid_c = np.random.uniform(-5, 15, n_combinations).astype(float)\n",
    "# grid_c = 2**grid_c\n",
    "\n",
    "# grid_gamma = np.random.uniform(-15, 3, n_combinations).astype(float)\n",
    "# grid_gamma = 2**grid_gamma\n",
    "\n",
    "# grid_episolon = np.random.uniform(0.05, 1.0, n_combinations).astype(float)\n",
    "\n",
    "# The best performing gamma value is: 0.01466\n",
    "# The best performing C value is: 593.42\n",
    "# The best performing epsilon value is:  0.16\n",
    "\n",
    "hyperparameters_grid = {'gamma': list(grid_gamma), \n",
    "                        'C': list(grid_c),\n",
    "                        'epsilon': list(grid_episolon)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing gamma value is: 0.00058\n",
      "The best performing C value is: 49.70\n",
      "The best performing epsilon value is:  0.77\n"
     ]
    }
   ],
   "source": [
    "# Run Grid Search\n",
    "randomCV = GridSearchCV(SVR(kernel='rbf'), param_grid=hyperparameters_grid, cv = 5)\n",
    "randomCV.fit(x_treino, y_treino)\n",
    " \n",
    "# Identify optimal hyperparameter values\n",
    "best_gamma  = randomCV.best_params_['gamma']\n",
    "best_C      = randomCV.best_params_['C']\n",
    "best_epsilon= randomCV.best_params_['epsilon']\n",
    " \n",
    "print(\"The best performing gamma value is: {:5.5f}\".format(best_gamma))\n",
    "print(\"The best performing C value is: {:5.2f}\".format(best_C))\n",
    "print(\"The best performing epsilon value is: {:5.2f}\".format(best_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3.6237947770473338\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "svr  = SVR(kernel='rbf', gamma=best_gamma, epsilon=best_epsilon, C=best_C)\n",
    "svr.fit(x_treino, y_treino)\n",
    "\n",
    "pred = svr.predict(x_teste)\n",
    "\n",
    "# print(regression.score(x_teste, y_teste))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_true=y_teste, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro algoritimo proposto foi a otimização bayesiana. Para a sua implementação utilziamos a biblioteca hyperopt, que dispnibiliza O regressor (TPE) para modelar a distribuição de probabilidades que é muito mais rápido que a implementação padrão utilizando “processos gaussianos”.\n",
    "\n",
    "Esta implementação foi feita em passos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir a Função de mínimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos pesquisar por Support Vector Machines (SVM), definimos um parâmetro params ['type'] como o nome do modelo, e uma função para executar o treinamento e retornar a precisão da validação cruzada. \n",
    "Como estamos tentando maximizar a precisão da validação cruzada, devemos negar esse valor para o hyperopt, pois o hyperopt sabe apenas como minimizar uma função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_status(clf,X_,y):\n",
    "    acc = cross_val_score(clf, X_, y, cv=5).mean()\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVR(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    accuracy = cross_val_score(clf, x_treino, y_treino).mean()\n",
    "    \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir espaço de pesquisa sobre os hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.uniform('C', (2**-5), (2**15)),\n",
    "        'gamma': hp.uniform('gamma', (2**-15), (2**3)),\n",
    "        'epsilon': hp.uniform('epsilon', 0.05, 1.0),\n",
    "        'kernel': hp.choice('kernel', ['rbf'])\n",
    "    },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionar um algoritimo de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas opções principais de algoritmos de busca são:\n",
    "\n",
    "    - hyperopt.tpe.suggest: Estimadores da Árvore de Parzen, uma abordagem bayesiana que seleciona iterativa e adaptativamente novas configurações de hiperparâmetro para explorar com base em resultados anteriores;\n",
    "    - hyperopt.rand.suggest: Pesquisa aleatória, uma abordagem não adaptativa que mostra o espaço de pesquisa.\n",
    "    \n",
    "Conforme pedido, utilziamos o algoritimo TPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executar o algoritmo de ajuste com hyperopt fmin ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos max_evals como o número máximo de pontos no espaço do hiperparâmetro para testar, ou seja, o número máximo de modelos para ajustar e avaliar.\n",
    "\n",
    "O SparkTrials usa 2 argumentos:\n",
    "    - parallelism: Número de modelos para ajustar e avaliar simultaneamente.\n",
    "    - timeout: tempo máximo (em segundos) que fmin pode demorar. Este argumento é opcional.\n",
    "\n",
    "O rastreamento automatizado do MLflow está ativado por padrão. Ligue para mlflow.start_run () antes de chamar fmin (), como mostra o exemplo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:20<00:00,  5.98trial/s, best loss: -0.512377857326078]  \n",
      "The best performing gamma value is: 0.00383\n",
      "The best performing C value is: 23889.46\n",
      "The best performing epsilon value is:  0.35\n"
     ]
    }
   ],
   "source": [
    "hypopt_trials = Trials()\n",
    " \n",
    "best_params = fmin(objective, search_space, algo=tpe.suggest, \n",
    "max_evals=125, trials= hypopt_trials)\n",
    " \n",
    "best_gamma  = best_params['gamma']\n",
    "best_C      = best_params['C']\n",
    "best_epsilon= best_params['epsilon']\n",
    " \n",
    "print(\"The best performing gamma value is: {:5.5f}\".format(best_gamma))\n",
    "print(\"The best performing C value is: {:5.2f}\".format(best_C))\n",
    "print(\"The best performing epsilon value is: {:5.2f}\".format(best_epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  4.424817673220065\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "svr  = SVR(kernel='rbf', gamma=best_gamma, epsilon=best_epsilon, C=best_C)\n",
    "svr.fit(x_treino, y_treino)\n",
    "\n",
    "pred = svr.predict(x_teste)\n",
    "\n",
    "# print(regression.score(x_teste, y_teste))\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_true=y_teste, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO...\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "C_MIN = 2**(-5)\n",
    "C_MAX = 2**15\n",
    "\n",
    "GAMMA_MIN = 2**(-15)\n",
    "GAMMA_MAX = 2**3\n",
    "\n",
    "EPSILON_MIN = 0.05\n",
    "EPSILON_MAX = 1.0\n",
    "\n",
    "lb = np.array([C_MIN, GAMMA_MIN, EPSILON_MIN])\n",
    "ub = np.array([C_MAX, GAMMA_MAX, EPSILON_MAX])\n",
    "\n",
    "# FUNCTION\n",
    "def svr_fun(X):\n",
    "    c = X[0]\n",
    "    g = X[1]\n",
    "    eps = X[2]\n",
    "    \n",
    "    svr  = SVR(kernel='rbf', C=c, gamma=g, epsilon=eps)\n",
    "    svr.fit(x_treino, y_treino)\n",
    "    \n",
    "    pred = svr.predict(x_teste)\n",
    "    mae = metrics.mean_absolute_error(y_true=y_teste, y_pred=pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "print(\"PSO...\")\n",
    "x_opt, y_opt = pso(svr_fun, lb, ub, swarmsize=11, maxiter=11)\n",
    "\n",
    "print(\" C optimal: \"+ str(x_opt[0])+\n",
    "     \"\\n Gamma Optimal: \"+ str(x_opt[1])+\n",
    "     \"\\n Epsilon Optimal: \"+ str(x_opt[2]))\n",
    "print(\"MAE: \", str(y_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a implementação dos Métodos de Simmulate Annealing e CMA-ES foi utilizado a biblioteca optuna.\n",
    "\n",
    "Para o método de Simulated Annealing a biblioteca fornece uma implementação via classe através dos chamados \"samplers\" para determinar os valores dos parâmetros a serem avaliados durante o teste. Para o Simmulated Annealing o sampler é implementado via classe explicitamente (vale ressaltar que estamos utilizando a implementação proposta pela própria documentação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedAnnealingSampler(optuna.samplers.BaseSampler):\n",
    "    def __init__(self, temperature=100):\n",
    "        self._rng = np.random.RandomState()\n",
    "        self._temperature = temperature  # Current temperature.\n",
    "        self._current_trial = None  # Current state.\n",
    "\n",
    "    def sample_relative(self, study, trial, search_space):\n",
    "        if search_space == {}:\n",
    "            return {}\n",
    "\n",
    "        #\n",
    "        # An implementation of SA algorithm.\n",
    "        #\n",
    "\n",
    "        # Calculate transition probability.\n",
    "        prev_trial = study.trials[-2]\n",
    "        if self._current_trial is None or prev_trial.value <= self._current_trial.value:\n",
    "            probability = 1.0\n",
    "        else:\n",
    "            probability = np.exp((self._current_trial.value - prev_trial.value) / self._temperature)\n",
    "        self._temperature *= 0.9  # Decrease temperature.\n",
    "\n",
    "        # Transit the current state if the previous result is accepted.\n",
    "        if self._rng.uniform(0, 1) < probability:\n",
    "            self._current_trial = prev_trial\n",
    "\n",
    "        # Sample parameters from the neighborhood of the current point.\n",
    "        #\n",
    "        # The sampled parameters will be used during the next execution of\n",
    "        # the objective function passed to the study.\n",
    "        params = {}\n",
    "        for param_name, param_distribution in search_space.items():\n",
    "            if not isinstance(param_distribution, optuna.distributions.UniformDistribution):\n",
    "                raise NotImplementedError('Only suggest_uniform() is supported')\n",
    "\n",
    "            current_value = self._current_trial.params[param_name]\n",
    "            width = (param_distribution.high - param_distribution.low) * 0.1\n",
    "            neighbor_low = max(current_value - width, param_distribution.low)\n",
    "            neighbor_high = min(current_value + width, param_distribution.high)\n",
    "            params[param_name] = self._rng.uniform(neighbor_low, neighbor_high)\n",
    "\n",
    "        return params\n",
    "\n",
    "    #\n",
    "    # The rest is boilerplate code and unrelated to SA algorithm.\n",
    "    #\n",
    "    def infer_relative_search_space(self, study, trial):\n",
    "        return optuna.samplers.intersection_search_space(study)\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        independent_sampler = optuna.samplers.RandomSampler()\n",
    "        return independent_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim o é necessário criar uma função objetivo a qual deseja-se otimizar, em nosso caso procuramos minimizar o Erro Médio Absoluto (MAE) com uma validação no conjunto de testes da aplicação dos hyperparâmetros encontrados para o problema do SVM Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    c = trial.suggest_uniform('c', 2**(-5),  2**15)\n",
    "    gamma = trial.suggest_uniform('gamma', 2**(-15),  2**3)    \n",
    "    epsilon = trial.suggest_uniform('epsilon', 0.05,  1.0)\n",
    "    \n",
    "    svr  = SVR(kernel='rbf', C=c, gamma=gamma, epsilon=epsilon)\n",
    "    svr.fit(x_treino, y_treino)\n",
    "    \n",
    "    pred = svr.predict(x_teste)\n",
    "    mae = metrics.mean_absolute_error(y_true=y_teste, y_pred=pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "\n",
    "sampler = SimulatedAnnealingSampler()\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo, como resultado os melhores parâmetros encontrados durante a busca são mostrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem como o resultado para o  erro absoluto médio (MAE) no conjunto de teste com esses parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhantemente ao algoritmo de Simullate Annealing, a implementação do algoritmo de otimização CMA-ES também foi feita via biblioteca optunza. A implementação porém é encapsulada em um sampler default fornecido pela própria biblioteca, assim não sendo necessário a implementação de uma classe sampler específica, somente a função objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    c = trial.suggest_uniform('c', 2**(-5),  2**15)\n",
    "    gamma = trial.suggest_uniform('gamma', 2**(-15),  2**3)    \n",
    "    epsilon = trial.suggest_uniform('epsilon', 0.05,  1.0)\n",
    "    \n",
    "    svr  = SVR(kernel='rbf', C=c, gamma=gamma, epsilon=epsilon)\n",
    "    svr.fit(x_treino, y_treino)\n",
    "    \n",
    "    pred = svr.predict(x_teste)\n",
    "    mae = metrics.mean_absolute_error(y_true=y_teste, y_pred=pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=125)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo, como resultado os melhores parâmetros encontrados durante a busca são mostrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem como o resultado para o  erro absoluto médio (MAE) no conjunto de teste com esses parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
